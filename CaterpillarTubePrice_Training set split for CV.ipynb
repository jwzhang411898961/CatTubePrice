{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "mac_path = \"/Users/jingweizhang/Dropbox/DataScience/Kaggle/CaterpillarTubePrice/competitions/caterpillar-tube-pricing/competition_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle data routine in case you saved the data in a local environment\n",
    "def load_data(pickle_file):\n",
    "    load_file=open(pickle_file,'rb')\n",
    "    data=cPickle.load(load_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_benchmark_data():\n",
    "    #data handling, take the input data, and merge them accordingly\n",
    "    #this is the original data handling routine of the xgb benchark script shared by Gilberto Titericz Junior\n",
    "    train = pd.read_csv(mac_path + '/train_set.csv', parse_dates=[2,])\n",
    "    test = pd.read_csv(mac_path + '/test_set.csv', parse_dates=[3,])\n",
    "    tube_data = pd.read_csv(mac_path + '/tube.csv')\n",
    "    bill_of_materials_data = pd.read_csv(mac_path + '/bill_of_materials.csv')\n",
    "    specs_data = pd.read_csv(mac_path + '/specs.csv')\n",
    "\n",
    "    train = pd.merge(train, tube_data, on = 'tube_assembly_id')\n",
    "    train = pd.merge(train, bill_of_materials_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, tube_data, on ='tube_assembly_id')\n",
    "    test = pd.merge(test, bill_of_materials_data, on ='tube_assembly_id')\n",
    "\n",
    "    train['year'] = train.quote_date.dt.year\n",
    "    train['month'] = train.quote_date.dt.month\n",
    "\n",
    "    test['year'] = test.quote_date.dt.year\n",
    "    test['month'] = test.quote_date.dt.month\n",
    "\n",
    "    # drop useless columns and create labels\n",
    "    idx = test.id.values.astype(int)\n",
    "    test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1, inplace=True)\n",
    "    labels = train.cost.values\n",
    "    # print(type(idx))\n",
    "\n",
    "    #for some reason material_id cannot be converted to categorical variable\n",
    "    train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis=1, inplace=True)\n",
    "\n",
    "    train['material_id'].replace(np.nan, ' ', regex=True, inplace=True)\n",
    "    test['material_id'].replace(np.nan, ' ', regex=True, inplace=True)\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        column_label = 'component_id_' + str(i)\n",
    "        train[column_label].replace(np.nan, ' ', regex=True, inplace=True)\n",
    "        test[column_label].replace(np.nan, ' ', regex=True, inplace=True)\n",
    "\n",
    "    train.fillna(0, inplace=True)\n",
    "    test.fillna(0, inplace=True)\n",
    "\n",
    "    # convert data to numpy array\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "\n",
    "    for i in range(train.shape[1]):\n",
    "        if i in [0,3,5,11,12,13,14,15,16,20,22,24,26,28,30,32,34]:\n",
    "            print(i,list(train[1:5,i]) + list(test[1:5,i]))\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[:, i]) + list(test[:, i]))\n",
    "            train[:, i] = lbl.transform(train[:, i])\n",
    "            test[:, i] = lbl.transform(test[:, i])\n",
    "\n",
    "    return train, test, idx, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb learner, inline with the xgb benchmark script shared by Gilberto Titericz Junior\n",
    "def xgb_learning(labels, train, test):\n",
    "    label_log = np.log1p(labels)\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"eta\"] = 0.1\n",
    "    params[\"min_child_weight\"] = 6\n",
    "    params[\"subsample\"] = 0.87\n",
    "    params[\"colsample_bytree\"] = 0.50\n",
    "    params[\"scale_pos_weight\"] = 1.0\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 7\n",
    "    params[\"seed\"]=3\n",
    "    \n",
    "    plst = list(params.items())\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(train, label_log)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "    \n",
    "    num_rounds = 120\n",
    "    \n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    preds1 = model.predict(xgtest)\n",
    "    preds = np.expm1(preds1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn LinearRegression\n",
    "def linear_learning(labels, train, test):\n",
    "    label_log = np.log1p(labels)\n",
    "    linear = LinearRegression()\n",
    "    model = linear.fit(train, label_log)\n",
    "    preds1 = model.predict(test)\n",
    "    preds = np.expm1(preds1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn svm regression \n",
    "def svm_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
    "        kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    model=clf.fit(train, label_log)\n",
    "\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn random forest regression\n",
    "def random_learning(labels, train, test):\n",
    "    label_log=np.log1p(labels)\n",
    "    clf=RandomForestRegressor(n_estimators=50, n_jobs=3)\n",
    "    model=clf.fit(train, label_log)\n",
    "    preds1=model.predict(test)\n",
    "    preds=np.expm1(preds1)\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066', 'S-0066']\n",
      "3 ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "5 ['SP-0019', 'SP-0019', 'SP-0019', 'SP-0019', 'SP-0035', 'SP-0035', 'SP-0035', 'SP-0035']\n",
      "11 ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "12 ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "13 ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "14 ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "15 ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003']\n",
      "16 ['EF-008', 'EF-008', 'EF-008', 'EF-008', 'EF-003', 'EF-003', 'EF-003', 'EF-003']\n",
      "20 ['C-1312', 'C-1312', 'C-1312', 'C-1312', 'C-1622', 'C-1622', 'C-1622', 'C-1622']\n",
      "22 [' ', ' ', ' ', ' ', 'C-1629', 'C-1629', 'C-1629', 'C-1629']\n",
      "24 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "26 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "28 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "30 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "32 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "34 [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "perform cross validation\n",
      "logistic regression score for test run 1 is 0.217290\n",
      "logistic regression score for test run 2 is 0.214908\n",
      "logistic regression score for test run 3 is 0.218768\n",
      "logistic regression score for test run 4 is 0.213344\n",
      "logistic regression score for test run 5 is 0.212562\n",
      "logistic regression score for test run 6 is 0.216825\n",
      "logistic regression score for test run 7 is 0.219061\n",
      "logistic regression score for test run 8 is 0.220987\n",
      "logistic regression score for test run 9 is 0.213738\n",
      "logistic regression score for test run 10 is 0.218089\n",
      "Mean logistic regression RMSE is 0.216557:\n",
      "it takes 17.435 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    test_run=True\n",
    "    train, test, idx, labels=xgb_benchmark_data()\n",
    "    \n",
    "    if test_run:\n",
    "        print('perform cross validation')\n",
    "        rmse = []\n",
    "        rnd_state = np.random.RandomState(42)\n",
    "        for run in range(1, 11):\n",
    "            train_i, test_i = train_test_split(np.arange(train.shape[0]), train_size = 0.8, random_state = rnd_state)\n",
    "            tr_train=train[train_i]\n",
    "            tr_test=train[test_i]\n",
    "            tr_train_y=labels[train_i]\n",
    "            tr_test_y=labels[test_i]\n",
    "            \n",
    "            # you can switch on/off each learninger as you wish by comment/uncomment\n",
    "            tr_preds=xgb_learning(tr_train_y, tr_train, tr_test)\n",
    "            \n",
    "            rmse_score = (np.sum((np.log1p(tr_preds)-np.log1p(tr_test_y))**2)/len(test_i))**0.5\n",
    "            \n",
    "            compare=pd.DataFrame({\"tr_test_id\":test_i, \"cost_real\":tr_test_y, \"cost_pred\":tr_preds})\n",
    "            header=[\"tr_test_id\", \"cost_real\", \"cost_pred\"]\n",
    "            compare.to_csv('compare.csv', columns=header, index=False)\n",
    "            rmse.append(rmse_score)\n",
    "            print (\"logistic regression score for test run %i is %.6f\" %(run, rmse_score))\n",
    "        print (\"Mean logistic regression RMSE is %.6f:\" %np.mean(rmse))\n",
    "    else:\n",
    "        preds=xgb_learning(labels, train, test)\n",
    "        preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "        preds.to_csv('xgb_test.csv', index=False)\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    print (\"it takes %.3f seconds\"  %(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3b77fa18a747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
